### Bias and Toxicity Analysis
Goal is to analyze bias and toxicity for Anthropic/hh-rlhf and allenai/real-toxicity-prompts datasets. We will be using [Unitary Detoxify](https://github.com/unitaryai/detoxify) library for evaluating toxicity. We have defined a dictionary (bias_category_descriptors.json) for classifying bias categories.

### Execution
Please follow readme instructions in individual dataset folder for execution
