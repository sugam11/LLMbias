{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f099387",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "454f4490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: HF_DATASETS_CACHE=\"/data/users/sgarg6/hf_cache\"\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"%env HF_DATASETS_CACHE=\\\"/data/users/sgarg6/hf_cache\\\"\";\n",
       "                var nbb_formatted_code = \"%env HF_DATASETS_CACHE=\\\"/data/users/sgarg6/hf_cache\\\"\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%env HF_DATASETS_CACHE=\"/data/users/sgarg6/hf_cache\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58bc9691",
   "metadata": {},
   "source": [
    "# Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f03240cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"import torch\\nfrom transformers import GPT2Tokenizer, GPT2ForSequenceClassification\\n\\ntokenizer = GPT2Tokenizer.from_pretrained(\\\"microsoft/DialogRPT-updown\\\")\\nmodel = GPT2ForSequenceClassification.from_pretrained(\\\"microsoft/DialogRPT-updown\\\")\\n\\n# default to left padding\\ntokenizer.padding_side = \\\"left\\\"\\n# Define PAD Token = EOS Token = 50256\\ntokenizer.pad_token = tokenizer.eos_token\\n# resize model embedding to match new tokenizer\\nmodel.resize_token_embeddings(len(tokenizer))\\n# fix model padding token id\\nmodel.config.pad_token_id = model.config.eos_token_id\";\n",
       "                var nbb_formatted_code = \"import torch\\nfrom transformers import GPT2Tokenizer, GPT2ForSequenceClassification\\n\\ntokenizer = GPT2Tokenizer.from_pretrained(\\\"microsoft/DialogRPT-updown\\\")\\nmodel = GPT2ForSequenceClassification.from_pretrained(\\\"microsoft/DialogRPT-updown\\\")\\n\\n# default to left padding\\ntokenizer.padding_side = \\\"left\\\"\\n# Define PAD Token = EOS Token = 50256\\ntokenizer.pad_token = tokenizer.eos_token\\n# resize model embedding to match new tokenizer\\nmodel.resize_token_embeddings(len(tokenizer))\\n# fix model padding token id\\nmodel.config.pad_token_id = model.config.eos_token_id\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2ForSequenceClassification\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"microsoft/DialogRPT-updown\")\n",
    "model = GPT2ForSequenceClassification.from_pretrained(\"microsoft/DialogRPT-updown\")\n",
    "\n",
    "# default to left padding\n",
    "tokenizer.padding_side = \"left\"\n",
    "# Define PAD Token = EOS Token = 50256\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "# resize model embedding to match new tokenizer\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "# fix model padding token id\n",
    "model.config.pad_token_id = model.config.eos_token_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29bd2fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.2981]])\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"inputs = tokenizer(\\\"Hello, my dog is cute\\\", return_tensors=\\\"pt\\\")\\n\\nwith torch.no_grad():\\n    logits = model(**inputs).logits\\n\\npredicted_class_id = logits.argmax().item()\\n\\nprint(logits)\";\n",
       "                var nbb_formatted_code = \"inputs = tokenizer(\\\"Hello, my dog is cute\\\", return_tensors=\\\"pt\\\")\\n\\nwith torch.no_grad():\\n    logits = model(**inputs).logits\\n\\npredicted_class_id = logits.argmax().item()\\n\\nprint(logits)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits\n",
    "\n",
    "predicted_class_id = logits.argmax().item()\n",
    "\n",
    "print(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e6c24e",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3929e13c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"from torch.utils.data import Dataset\\nfrom datasets import load_dataset\\n\\n\\nclass AnthropicDataset(Dataset):\\n    def __init__(self, split=\\\"test\\\"):\\n        assert split in (\\\"train\\\", \\\"test\\\")\\n        major_split = split if \\\"train\\\" == split else \\\"test\\\"\\n        dataset = load_dataset(\\\"Anthropic/hh-rlhf\\\")[major_split]\\n        self.data = []\\n        for data in dataset:\\n            self.data.append((data[\\\"chosen\\\"], 1))\\n            self.data.append((data[\\\"rejected\\\"], 0))\\n\\n    def __len__(self):\\n        return len(self.data)\\n\\n    def __getitem__(self, index):\\n        sample, label = self.data[index]\\n\\n        return sample, label\";\n",
       "                var nbb_formatted_code = \"from torch.utils.data import Dataset\\nfrom datasets import load_dataset\\n\\n\\nclass AnthropicDataset(Dataset):\\n    def __init__(self, split=\\\"test\\\"):\\n        assert split in (\\\"train\\\", \\\"test\\\")\\n        major_split = split if \\\"train\\\" == split else \\\"test\\\"\\n        dataset = load_dataset(\\\"Anthropic/hh-rlhf\\\")[major_split]\\n        self.data = []\\n        for data in dataset:\\n            self.data.append((data[\\\"chosen\\\"], 1))\\n            self.data.append((data[\\\"rejected\\\"], 0))\\n\\n    def __len__(self):\\n        return len(self.data)\\n\\n    def __getitem__(self, index):\\n        sample, label = self.data[index]\\n\\n        return sample, label\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "class AnthropicDataset(Dataset):\n",
    "    def __init__(self, split=\"test\"):\n",
    "        assert split in (\"train\", \"test\")\n",
    "        major_split = split if \"train\" == split else \"test\"\n",
    "        dataset = load_dataset(\"Anthropic/hh-rlhf\")[major_split]\n",
    "        self.data = []\n",
    "        for data in dataset:\n",
    "            self.data.append((data[\"chosen\"], 1))\n",
    "            self.data.append((data[\"rejected\"], 0))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sample, label = self.data[index]\n",
    "\n",
    "        return sample, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f68fa25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration Anthropic--hh-rlhf-c8cd8dc58ab67414\n",
      "Found cached dataset json (/soe/sgarg6/course_work/244_nlp/LLMbias/\"/data/users/sgarg6/hf_cache\"/Anthropic___json/Anthropic--hh-rlhf-c8cd8dc58ab67414/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54973dc752e14c4eafc1d962b56f436b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration Anthropic--hh-rlhf-c8cd8dc58ab67414\n",
      "Found cached dataset json (/soe/sgarg6/course_work/244_nlp/LLMbias/\"/data/users/sgarg6/hf_cache\"/Anthropic___json/Anthropic--hh-rlhf-c8cd8dc58ab67414/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b132ad6baea4250979fa0e9ff4b5013",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"train_data = AnthropicDataset(\\\"train\\\")\\ntest_data = AnthropicDataset(\\\"test\\\")\";\n",
       "                var nbb_formatted_code = \"train_data = AnthropicDataset(\\\"train\\\")\\ntest_data = AnthropicDataset(\\\"test\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data = AnthropicDataset(\"train\")\n",
    "test_data = AnthropicDataset(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "090f3b95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"device = \\\"cuda\\\" if torch.cuda.is_available() else \\\"cpu\\\"\";\n",
       "                var nbb_formatted_code = \"device = \\\"cuda\\\" if torch.cuda.is_available() else \\\"cpu\\\"\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96fff3e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"def collate_data(data):\\n    text_samples = [sample[0] for sample in data]\\n    labels = torch.tensor([sample[1] for sample in data], dtype=torch.float).to(device)\\n    tokens = tokenizer(\\n        text_samples,\\n        return_tensors=\\\"pt\\\",\\n        truncation=True,\\n        padding=True,\\n        max_length=512,\\n    ).to(device)\\n    return tokens, labels\";\n",
       "                var nbb_formatted_code = \"def collate_data(data):\\n    text_samples = [sample[0] for sample in data]\\n    labels = torch.tensor([sample[1] for sample in data], dtype=torch.float).to(device)\\n    tokens = tokenizer(\\n        text_samples,\\n        return_tensors=\\\"pt\\\",\\n        truncation=True,\\n        padding=True,\\n        max_length=512,\\n    ).to(device)\\n    return tokens, labels\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def collate_data(data):\n",
    "    text_samples = [sample[0] for sample in data]\n",
    "    labels = torch.tensor([sample[1] for sample in data], dtype=torch.float).to(device)\n",
    "    tokens = tokenizer(\n",
    "        text_samples,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=512,\n",
    "    ).to(device)\n",
    "    return tokens, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eef62f4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"from torch.utils.data import DataLoader\\n\\n# train_dataloader = DataLoader(train_data, collate_fn=collate_data, batch_size=2)\";\n",
       "                var nbb_formatted_code = \"from torch.utils.data import DataLoader\\n\\n# train_dataloader = DataLoader(train_data, collate_fn=collate_data, batch_size=2)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# train_dataloader = DataLoader(train_data, collate_fn=collate_data, batch_size=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73054692",
   "metadata": {},
   "source": [
    "# Setup Hyper Params and Model Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9812f696",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"best_val_loss = 99999\\nBATCH_SIZE = 8\\nEPOCHS = 1\\nlearning_rate = 0.01\";\n",
       "                var nbb_formatted_code = \"best_val_loss = 99999\\nBATCH_SIZE = 8\\nEPOCHS = 1\\nlearning_rate = 0.01\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_val_loss = 99999\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 1\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f452c705",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msugam110795\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.14.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/soe/sgarg6/course_work/244_nlp/LLMbias/wandb/run-20230322_185026-jkodi1ma</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sugam110795/nlp244/runs/jkodi1ma' target=\"_blank\">polar-puddle-13</a></strong> to <a href='https://wandb.ai/sugam110795/nlp244' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sugam110795/nlp244' target=\"_blank\">https://wandb.ai/sugam110795/nlp244</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sugam110795/nlp244/runs/jkodi1ma' target=\"_blank\">https://wandb.ai/sugam110795/nlp244/runs/jkodi1ma</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/sugam110795/nlp244/runs/jkodi1ma?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7fe350ed1ea0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"import wandb\\n\\nwandb.init(\\n    entity=\\\"sugam110795\\\",\\n    project=\\\"nlp244\\\",\\n    group=\\\"LLMbias\\\",\\n    config={\\n        \\\"epochs\\\": EPOCHS,\\n        \\\"batch_size\\\": BATCH_SIZE,\\n        \\\"lr\\\": learning_rate,\\n    },\\n)\";\n",
       "                var nbb_formatted_code = \"import wandb\\n\\nwandb.init(\\n    entity=\\\"sugam110795\\\",\\n    project=\\\"nlp244\\\",\\n    group=\\\"LLMbias\\\",\\n    config={\\n        \\\"epochs\\\": EPOCHS,\\n        \\\"batch_size\\\": BATCH_SIZE,\\n        \\\"lr\\\": learning_rate,\\n    },\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.init(\n",
    "    entity=\"sugam110795\",\n",
    "    project=\"nlp244\",\n",
    "    group=\"LLMbias\",\n",
    "    config={\n",
    "        \"epochs\": EPOCHS,\n",
    "        \"batch_size\": BATCH_SIZE,\n",
    "        \"lr\": learning_rate,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7428793",
   "metadata": {},
   "source": [
    "# Model Train Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc36ed85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"def free_memory():\\n    import gc\\n\\n    torch.cuda.empty_cache()\\n    gc.collect()\";\n",
       "                var nbb_formatted_code = \"def free_memory():\\n    import gc\\n\\n    torch.cuda.empty_cache()\\n    gc.collect()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def free_memory():\n",
    "    import gc\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a77c3281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"from tqdm import tqdm\\nimport time\\nfrom sklearn.metrics import accuracy_score\\nfrom sklearn.metrics import f1_score\\n\\n\\ndef evaluate(model, data_loader, criterion):\\n    model.eval()\\n    total_loss = 0.0\\n    start_time = time.time()\\n    out = []\\n    label = []\\n    for batch, (X, y) in enumerate(tqdm(data_loader)):\\n        model.zero_grad()\\n        output = model(**X).logits\\n        loss = criterion(output.reshape(-1), y)\\n        total_loss += loss.item()\\n        pred = torch.sigmoid(output) > 0.5\\n        out.extend(pred.long().detach().tolist())\\n        label.extend(y.long().detach().tolist())\\n        del X, y, output, loss\\n        free_memory()\\n    acc = accuracy_score(label, out)\\n    f1 = f1_score(label, out)\\n    return total_loss / batch, acc, f1\";\n",
       "                var nbb_formatted_code = \"from tqdm import tqdm\\nimport time\\nfrom sklearn.metrics import accuracy_score\\nfrom sklearn.metrics import f1_score\\n\\n\\ndef evaluate(model, data_loader, criterion):\\n    model.eval()\\n    total_loss = 0.0\\n    start_time = time.time()\\n    out = []\\n    label = []\\n    for batch, (X, y) in enumerate(tqdm(data_loader)):\\n        model.zero_grad()\\n        output = model(**X).logits\\n        loss = criterion(output.reshape(-1), y)\\n        total_loss += loss.item()\\n        pred = torch.sigmoid(output) > 0.5\\n        out.extend(pred.long().detach().tolist())\\n        label.extend(y.long().detach().tolist())\\n        del X, y, output, loss\\n        free_memory()\\n    acc = accuracy_score(label, out)\\n    f1 = f1_score(label, out)\\n    return total_loss / batch, acc, f1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "def evaluate(model, data_loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    start_time = time.time()\n",
    "    out = []\n",
    "    label = []\n",
    "    for batch, (X, y) in enumerate(tqdm(data_loader)):\n",
    "        model.zero_grad()\n",
    "        output = model(**X).logits\n",
    "        loss = criterion(output.reshape(-1), y)\n",
    "        total_loss += loss.item()\n",
    "        pred = torch.sigmoid(output) > 0.5\n",
    "        out.extend(pred.long().detach().tolist())\n",
    "        label.extend(y.long().detach().tolist())\n",
    "        del X, y, output, loss\n",
    "        free_memory()\n",
    "    acc = accuracy_score(label, out)\n",
    "    f1 = f1_score(label, out)\n",
    "    return total_loss / batch, acc, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "480259cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"from tqdm import tqdm\\nimport time\\n\\n\\ndef train_step(\\n    data_loader, model, epoch, criterion, optimizer, eval_step, eval_data_loader, lr\\n):\\n    model.train()\\n    total_loss = 0.0\\n    start_time = time.time()\\n    prev_val_loss = 100\\n    for batch, (X, y) in tqdm(enumerate(data_loader)):\\n        model.zero_grad()\\n        output = model(**X).logits\\n        loss = criterion(output.reshape(-1), y)\\n        loss.backward()\\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\\n        optimizer.step()\\n        total_loss += loss.item()\\n        metrics = {\\\"train/train_loss\\\": loss.item(), \\\"train/step\\\": (batch + 1)}\\n        wandb.log(metrics)\\n        if batch % eval_step == 0 and batch > 0:\\n            cur_loss = loss.item()\\n            elapsed = time.time() - start_time\\n            print(\\\"| epoch {:3d} |\\\" \\\" loss {:5.2f}\\\".format(epoch, cur_loss))\\n            val_loss, acc, f1 = evaluate(model, eval_data_loader, criterion)\\n            if batch > 5000 and val_loss > prev_val_loss:\\n                for param_group in optimizer.param_groups:\\n                    param_group[\\\"lr\\\"] = lr * 0.1\\n                    lr *= 0.1\\n            prev_val_loss = val_loss\\n            wandb.log(\\n                {\\n                    \\\"eval/eval_loss\\\": val_loss,\\n                    \\\"eval/acc\\\": acc,\\n                    \\\"eval/f1\\\": f1,\\n                }\\n            )\\n        del loss, X, y, output\\n        free_memory()\\n        if lr < 0.00001:\\n            # Early Stopping\\n            break\\n    return total_loss / batch\";\n",
       "                var nbb_formatted_code = \"from tqdm import tqdm\\nimport time\\n\\n\\ndef train_step(\\n    data_loader, model, epoch, criterion, optimizer, eval_step, eval_data_loader, lr\\n):\\n    model.train()\\n    total_loss = 0.0\\n    start_time = time.time()\\n    prev_val_loss = 100\\n    for batch, (X, y) in tqdm(enumerate(data_loader)):\\n        model.zero_grad()\\n        output = model(**X).logits\\n        loss = criterion(output.reshape(-1), y)\\n        loss.backward()\\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\\n        optimizer.step()\\n        total_loss += loss.item()\\n        metrics = {\\\"train/train_loss\\\": loss.item(), \\\"train/step\\\": (batch + 1)}\\n        wandb.log(metrics)\\n        if batch % eval_step == 0 and batch > 0:\\n            cur_loss = loss.item()\\n            elapsed = time.time() - start_time\\n            print(\\\"| epoch {:3d} |\\\" \\\" loss {:5.2f}\\\".format(epoch, cur_loss))\\n            val_loss, acc, f1 = evaluate(model, eval_data_loader, criterion)\\n            if batch > 5000 and val_loss > prev_val_loss:\\n                for param_group in optimizer.param_groups:\\n                    param_group[\\\"lr\\\"] = lr * 0.1\\n                    lr *= 0.1\\n            prev_val_loss = val_loss\\n            wandb.log(\\n                {\\n                    \\\"eval/eval_loss\\\": val_loss,\\n                    \\\"eval/acc\\\": acc,\\n                    \\\"eval/f1\\\": f1,\\n                }\\n            )\\n        del loss, X, y, output\\n        free_memory()\\n        if lr < 0.00001:\\n            # Early Stopping\\n            break\\n    return total_loss / batch\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "\n",
    "def train_step(\n",
    "    data_loader, model, epoch, criterion, optimizer, eval_step, eval_data_loader, lr\n",
    "):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    start_time = time.time()\n",
    "    prev_val_loss = 100\n",
    "    for batch, (X, y) in tqdm(enumerate(data_loader)):\n",
    "        model.zero_grad()\n",
    "        output = model(**X).logits\n",
    "        loss = criterion(output.reshape(-1), y)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        metrics = {\"train/train_loss\": loss.item(), \"train/step\": (batch + 1)}\n",
    "        wandb.log(metrics)\n",
    "        if batch % eval_step == 0 and batch > 0:\n",
    "            cur_loss = loss.item()\n",
    "            elapsed = time.time() - start_time\n",
    "            print(\"| epoch {:3d} |\" \" loss {:5.2f}\".format(epoch, cur_loss))\n",
    "            val_loss, acc, f1 = evaluate(model, eval_data_loader, criterion)\n",
    "            if batch > 5000 and val_loss > prev_val_loss:\n",
    "                for param_group in optimizer.param_groups:\n",
    "                    param_group[\"lr\"] = lr * 0.1\n",
    "                    lr *= 0.1\n",
    "            prev_val_loss = val_loss\n",
    "            wandb.log(\n",
    "                {\n",
    "                    \"eval/eval_loss\": val_loss,\n",
    "                    \"eval/acc\": acc,\n",
    "                    \"eval/f1\": f1,\n",
    "                }\n",
    "            )\n",
    "        del loss, X, y, output\n",
    "        free_memory()\n",
    "        if lr < 0.00001:\n",
    "            # Early Stopping\n",
    "            break\n",
    "    return total_loss / batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07109c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread SystemMonitor:\n",
      "Traceback (most recent call last):\n",
      "  File \"/soe/sgarg6/conda/envs/nlp_env/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/soe/sgarg6/conda/envs/nlp_env/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/soe/sgarg6/conda/envs/nlp_env/lib/python3.10/site-packages/wandb/sdk/internal/system/system_monitor.py\", line 118, in _start\n",
      "    asset.start()\n",
      "  File \"/soe/sgarg6/conda/envs/nlp_env/lib/python3.10/site-packages/wandb/sdk/internal/system/assets/cpu.py\", line 166, in start\n",
      "    self.metrics_monitor.start()\n",
      "  File \"/soe/sgarg6/conda/envs/nlp_env/lib/python3.10/site-packages/wandb/sdk/internal/system/assets/interfaces.py\", line 168, in start\n",
      "    logger.info(f\"Started {self._process.name}\")\n",
      "AttributeError: 'NoneType' object has no attribute 'name'\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"config = wandb.config\";\n",
       "                var nbb_formatted_code = \"config = wandb.config\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config = wandb.config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a5699f",
   "metadata": {},
   "source": [
    "# Train Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf3dfaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "260it [06:33,  1.60s/it]"
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data_utils\n",
    "\n",
    "\n",
    "model = model.to(device)\n",
    "optimizer = Adam(model.parameters(), lr=config.lr)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "for epoch in range(config.epochs):\n",
    "    epoch_start_time = time.time()\n",
    "    train_dataloader = DataLoader(\n",
    "        train_data, batch_size=config.batch_size, shuffle=True, collate_fn=collate_data\n",
    "    )\n",
    "    valid_dataloader = DataLoader(\n",
    "        test_data, batch_size=config.batch_size, shuffle=True, collate_fn=collate_data\n",
    "    )\n",
    "    train_loss = train_step(\n",
    "        train_dataloader,\n",
    "        model,\n",
    "        epoch,\n",
    "        criterion,\n",
    "        optimizer,\n",
    "        500,\n",
    "        valid_dataloader,\n",
    "        config.lr,\n",
    "    )\n",
    "\n",
    "    # End of training\n",
    "    val_loss, acc, f1 = evaluate(model, valid_dataloader, criterion)\n",
    "    print(\"-\" * 89)\n",
    "    print(\n",
    "        \"| end of epoch {:3d} | time: {:5.2f}s | valid loss {:5.2f} | \"\n",
    "        \" acc {:5.2f}\".format(epoch, (time.time() - epoch_start_time), val_loss, acc)\n",
    "    )\n",
    "    print(f\"F1-score is {f1}\")\n",
    "    print(\"-\" * 89)\n",
    "    # Save the model if the validation loss is the best we've seen so far.\n",
    "    if val_loss < best_val_loss:\n",
    "        with open(\"/data/users/sgarg6/trained_models/gpt-reward/model.pt\", \"wb\") as f:\n",
    "            torch.save(model, f)\n",
    "        best_val_loss = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ff2ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss, acc, f1 = evaluate(model, valid_dataloader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dceb51bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.summary['val_loss'] = val_loss\n",
    "wandb.summary['val_acc'] = acc\n",
    "wandb.summary['val_f1'] = f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b736c94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(val_loss, acc, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b902ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\").to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits\n",
    "\n",
    "print(torch.sigmoiod(logits))\n",
    "predicted_class_id = logits.argmax().item()\n",
    "print(predicted_class_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23651505",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.push_to_hub(\"sugam11/gpt2-rlhf-reward\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b069ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
